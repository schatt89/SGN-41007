{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 0 (pen & paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/anna/miniconda3/envs/main/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "\n",
    "model = tf.keras.Sequential([])\n",
    "N = 10 # Number of feature maps\n",
    "w, h = 5, 5 # Conv. window size\n",
    "\n",
    "model.add(Conv2D(N, (w, h),\n",
    "    input_shape=(64, 64, 3),\n",
    "    activation = 'relu',\n",
    "    padding = 'same'))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(N, (w, h),\n",
    "    activation = 'relu',\n",
    "    padding = 'same'))\n",
    "\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(2, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 64, 64, 10)        760       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 32, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 10)        2510      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 5122      \n",
      "=================================================================\n",
      "Total params: 8,392\n",
      "Trainable params: 8,392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760 0 2510 0 0 5122\n"
     ]
    }
   ],
   "source": [
    "n_conv1 = ((5*5*3)*10) + 10\n",
    "n_conv2 = ((5*5*10)*10) + 10\n",
    "n_dense = ((1*1*2560)*2) + 2\n",
    "\n",
    "print(n_conv1, 0, n_conv2, 0, 0, n_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([])\n",
    "N = 32 # Number of feature maps\n",
    "w, h = 5, 5 # Conv. window size\n",
    "\n",
    "model.add(Conv2D(N, (w, h),\n",
    "    input_shape=(64, 64, 3),\n",
    "    activation = 'relu',\n",
    "    padding = 'same'))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(4, 4)))\n",
    "\n",
    "model.add(Conv2D(N, (w, h),\n",
    "    activation = 'relu',\n",
    "    padding = 'same'))\n",
    "\n",
    "model.add(MaxPool2D((4,4)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100, activation = 'sigmoid')) # new dense layer\n",
    "\n",
    "model.add(Dense(2, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 64, 64, 32)        2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 16, 16, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               51300     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 79,566\n",
      "Trainable params: 79,566\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (202, 64, 64)\n",
      "y shape: (202,)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Jan 24 08:48:51 2019\n",
    "\n",
    "@author: hehu\n",
    "\"\"\"\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#from simplelbp import local_binary_pattern\n",
    "\n",
    "def load_data(folder):\n",
    "    \"\"\" \n",
    "    Load all images from subdirectories of\n",
    "    'folder'. The subdirectory name indicates\n",
    "    the class.\n",
    "    \"\"\"\n",
    "    \n",
    "    X = []          # Images go here\n",
    "    y = []          # Class labels go here\n",
    "    classes = []    # All class names go here\n",
    "    \n",
    "    subdirectories = glob.glob(folder + \"/*\")\n",
    "    \n",
    "    # Loop over all folders\n",
    "    for d in subdirectories:\n",
    "        \n",
    "        # Find all files from this folder\n",
    "        files = glob.glob(d + os.sep + \"*.jpg\")\n",
    "        \n",
    "        # Load all files\n",
    "        for name in files:\n",
    "            \n",
    "            # Load image and parse class name\n",
    "            img = plt.imread(name)\n",
    "            class_name = name.split(os.sep)[-2]\n",
    "\n",
    "            # Convert class names to integer indices:\n",
    "            if class_name not in classes:\n",
    "                classes.append(class_name)\n",
    "            \n",
    "            class_idx = classes.index(class_name)\n",
    "            \n",
    "            X.append(img)\n",
    "            y.append(class_idx)\n",
    "    \n",
    "    # Convert python lists to contiguous numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Test our loader\n",
    "\n",
    "X, y = load_data(\"Ex3_data/GTSRB_subset\")\n",
    "print(\"X shape: \" + str(X.shape))\n",
    "print(\"y shape: \" + str(y.shape))\n",
    "# Continue your code here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "X, y = shuffle(X, y, random_state=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "X_train = np.tile(X_train, [1, 1, 1, 3])\n",
    "X_test = np.tile(X_test, [1, 1, 1, 3])\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((141, 64, 64, 3), (141, 2))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 141 samples, validate on 61 samples\n",
      "Epoch 1/20\n",
      "141/141 [==============================] - 1s 10ms/sample - loss: 0.6988 - acc: 0.5674 - val_loss: 0.6355 - val_acc: 0.6557\n",
      "Epoch 2/20\n",
      "141/141 [==============================] - 0s 3ms/sample - loss: 0.5440 - acc: 0.7660 - val_loss: 0.4646 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "141/141 [==============================] - 0s 3ms/sample - loss: 0.4537 - acc: 0.8298 - val_loss: 0.3757 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "141/141 [==============================] - 0s 3ms/sample - loss: 0.2861 - acc: 0.8440 - val_loss: 0.1598 - val_acc: 0.9344\n",
      "Epoch 5/20\n",
      "141/141 [==============================] - 0s 3ms/sample - loss: 0.1267 - acc: 0.9504 - val_loss: 0.0946 - val_acc: 0.9836\n",
      "Epoch 6/20\n",
      "141/141 [==============================] - 0s 3ms/sample - loss: 0.0874 - acc: 0.9858 - val_loss: 0.0614 - val_acc: 0.9836\n",
      "Epoch 7/20\n",
      "141/141 [==============================] - 0s 3ms/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.0367 - val_acc: 0.9836\n",
      "Epoch 8/20\n",
      "141/141 [==============================] - 0s 3ms/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0245 - val_acc: 0.9836\n",
      "Epoch 9/20\n",
      "141/141 [==============================] - 0s 3ms/sample - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 0.9836\n",
      "Epoch 10/20\n",
      "141/141 [==============================] - 0s 3ms/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0209 - val_acc: 0.9836\n",
      "Epoch 11/20\n",
      "141/141 [==============================] - 0s 3ms/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0280 - val_acc: 0.9836\n",
      "Epoch 12/20\n",
      "141/141 [==============================] - 0s 3ms/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0243 - val_acc: 0.9836\n",
      "Epoch 13/20\n",
      "141/141 [==============================] - 0s 3ms/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 0.9836\n",
      "Epoch 14/20\n",
      "141/141 [==============================] - 0s 3ms/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 0.9836\n",
      "Epoch 15/20\n",
      "141/141 [==============================] - 0s 3ms/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 0.9836\n",
      "Epoch 16/20\n",
      "141/141 [==============================] - 0s 3ms/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0243 - val_acc: 0.9836\n",
      "Epoch 17/20\n",
      "141/141 [==============================] - 0s 3ms/sample - loss: 9.6868e-04 - acc: 1.0000 - val_loss: 0.0219 - val_acc: 0.9836\n",
      "Epoch 18/20\n",
      "141/141 [==============================] - 0s 3ms/sample - loss: 9.1705e-04 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 0.9836\n",
      "Epoch 19/20\n",
      "141/141 [==============================] - 0s 3ms/sample - loss: 8.3990e-04 - acc: 1.0000 - val_loss: 0.0244 - val_acc: 0.9836\n",
      "Epoch 20/20\n",
      "141/141 [==============================] - 0s 3ms/sample - loss: 7.6315e-04 - acc: 1.0000 - val_loss: 0.0240 - val_acc: 0.9836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a66968d90>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training code:\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# The code is compiled to CUDA or C++\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=sgd, metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs = 20, batch_size = 2,  validation_data = [X_test, y_test]) # takes a few seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277.2588722239781"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.array([[0.0], [0.0]])\n",
    "def log_loss(w, X, y):\n",
    "    \"\"\" \n",
    "    Computes the log-loss function at w. The \n",
    "    computation uses the data in X with\n",
    "    corresponding labels in y. \n",
    "    \"\"\"\n",
    "\n",
    "    # Accumulate loss terms here.\n",
    "\n",
    "    # TODO: Sum up the loss for each sample in X to L\n",
    "    \n",
    "    # [N, 1]\n",
    "    loss = np.log(1 + np.exp(-y * X.dot(w)))\n",
    "    \n",
    "    # [1]\n",
    "    L = np.sum(loss)\n",
    "\n",
    "    return L\n",
    "\n",
    "log_loss(w, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.27485926, -1.04426743])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grad(w, X, y):\n",
    "    \"\"\" \n",
    "    Computes the gradient of the log-loss function\n",
    "    at w. The computation uses the data in X with\n",
    "    corresponding labels in y. \n",
    "    \"\"\"\n",
    "\n",
    "    # Accumulate gradient here.\n",
    "\n",
    "    # TODO: Sum up the gradient for each sample in X to G\n",
    "    \n",
    "    # [N, 2]\n",
    "    g = -y*X / (1 + np.exp(-y * X.dot(w))) * np.exp(-y * X.dot(w))\n",
    "    G = np.sum(g, axis = 0) / len(X)\n",
    "\n",
    "    return G\n",
    "\n",
    "grad(w, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load required packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def log_loss(w, X, y):\n",
    "    \"\"\" \n",
    "    Computes the log-loss function at w. The \n",
    "    computation uses the data in X with\n",
    "    corresponding labels in y. \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Accumulate loss terms here.\n",
    "\n",
    "    # TODO: Sum up the loss for each sample in X to L\n",
    "    \n",
    "    # [N, 1]\n",
    "    loss = np.log(1 + np.exp(-y * X.dot(w)))\n",
    "    \n",
    "    # [1]\n",
    "    L = np.sum(loss)\n",
    "\n",
    "    return L\n",
    "\n",
    "\n",
    "def grad(w, X, y):\n",
    "    \"\"\" \n",
    "    Computes the gradient of the log-loss function\n",
    "    at w. The computation uses the data in X with\n",
    "    corresponding labels in y. \n",
    "    \"\"\"\n",
    "\n",
    "    # Accumulate gradient here.\n",
    "\n",
    "    # TODO: Sum up the gradient for each sample in X to G\n",
    "    \n",
    "    # [N, 2]\n",
    "    g = -y*X / (1 + np.exp(-y * X.dot(w))) * np.exp(-y * X.dot(w))\n",
    "    G = np.sum(g, axis = 0) / len(X)\n",
    "    G = G.reshape([2, 1])\n",
    "\n",
    "    return G\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # TODO: Add your code here:\n",
    "\n",
    "    # 1) Load X and y data:\n",
    "    import csv\n",
    "\n",
    "    with open('Ex4_data/X.csv', newline='') as csvfile:\n",
    "        X = np.array(list(csv.reader(csvfile))).astype(float)\n",
    "    \n",
    "    with open('Ex4_data/y.csv', newline='') as csvfile:\n",
    "        y = np.array(list(csv.reader(csvfile))).astype(float)\n",
    "\n",
    "    # 2) Initialize w at random:\n",
    "    w = np.array([[0.], [0.]])\n",
    "    \n",
    "    w_array = [w]\n",
    "\n",
    "    # 3) Set step_size to a small positive value\n",
    "    \n",
    "    step_size = 0.1\n",
    "\n",
    "    # 4) Initialize empty lists for storing the path and\n",
    "    # accuracies:\n",
    "    \n",
    "    path = []\n",
    "    accuracy_list = []\n",
    "    y_10 = np.array(y)\n",
    "    y_10[y_10 == -1] = 0\n",
    "    \n",
    "    y = y.reshape(-1, 1)\n",
    "\n",
    "    for iteration in range(100):\n",
    "    \n",
    "        \n",
    "        # 5) Apply the gradient descent rule:\n",
    "        g = grad(w_array[iteration], X, y)\n",
    "        w = w_array[iteration] - g * step_size\n",
    "        w_array.append(w)\n",
    "        # 6) Print the current state:\n",
    "        # 7) Compute the accuracy:\n",
    "        \n",
    "        y_pred = 1 / (1 + np.exp(-X.dot(w)))\n",
    "        \n",
    "        acc = accuracy_score(np.round(y_pred), y_10)\n",
    "        accuracy_list.append(acc)\n",
    "        \n",
    "    # 8) Below is a template for plotting. Feel free to\n",
    "    # rewrite if you prefer different style:\n",
    "    w_array = np.array(w_array)\n",
    "    accuracy_list = np.array(accuracy_list)\n",
    "    \n",
    "    plt.figure(figsize=[5, 5])\n",
    "    plt.subplot(211)\n",
    "    plt.plot(w_array[:, 0], w_array[:, 1], 'ro-')\n",
    "    plt.xlabel('w$_0$')\n",
    "    plt.ylabel('w$_1$')\n",
    "    plt.title('Optimization path')\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.plot(100.0 * np.array(accuracy_list), linewidth=2)\n",
    "    plt.ylabel('Accuracy / %')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"log_loss_minimization.pdf\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
